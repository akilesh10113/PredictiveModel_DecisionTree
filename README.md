# 🧠 Predicting Outcomes Using Decision Tree Classifier | Python

This project applies a **Decision Tree Classifier** to predict outcomes based on structured data. The model uses entropy as the splitting criterion and is implemented using Scikit-learn in Python. It effectively handles classification tasks and provides a clear visual representation of decision logic.

---

## 📊 Dataset

The dataset used in this project includes:

- **Feature columns**: Structured numerical values representing input variables
- **Target column**: Class labels for prediction (e.g., binary or multi-class)

This is a **supervised classification problem**.

---

## 🧰 Libraries Used

- Python 3.x  
- `pandas`  
- `numpy`  
- `matplotlib`  
- `seaborn`  
- `scikit-learn` (`sklearn`)

---

## ⚙️ Project Steps

1. Data preprocessing and visualization  
2. Train-Test split using `train_test_split`  
3. Fitting the **Decision Tree Classifier** (criterion = `'entropy'`)  
4. Predicting outcomes on test data  
5. Confusion matrix and accuracy score evaluation  
6. Plotting prediction outputs  
7. (Optional) Predicting on new input values

---

## 📃 `requirements.txt`

- numpy
- pandas
- scikit-learn
- matplotlib
- seaborn

---

## ✅ Model Accuracy

The Decision Tree model achieved **97.36% accuracy** on the test set, showing strong classification performance using a single, interpretable tree structure.

---

## 📸 Sample Output

Below is a sample output from the project showing the final accuracy and a performance plot:

![Decision Tree Result](<img width="466" height="541" alt="Decision Tree" src="https://github.com/user-attachments/assets/d0dc4ab9-c27c-4d41-b348-f9d99a37025c" />
)
